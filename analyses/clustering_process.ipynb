{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Superstore Sales: Clustering Process"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from helper_funcs import *\n",
    "from sqlalchemy import create_engine, types\n",
    "from sqlalchemy.types import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# SQLAlchemy Engine\n",
    "engine = create_engine(generate_url())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General EDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table features not found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_sql_table\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfeatures\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m df\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m5\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PyRa3_10\\lib\\site-packages\\pandas\\io\\sql.py:282\u001B[0m, in \u001B[0;36mread_sql_table\u001B[1;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001B[0m\n\u001B[0;32m    280\u001B[0m pandas_sql \u001B[38;5;241m=\u001B[39m pandasSQL_builder(con, schema\u001B[38;5;241m=\u001B[39mschema)\n\u001B[0;32m    281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m pandas_sql\u001B[38;5;241m.\u001B[39mhas_table(table_name):\n\u001B[1;32m--> 282\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtable_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    284\u001B[0m \u001B[38;5;66;03m# error: Item \"SQLiteDatabase\" of \"Union[SQLDatabase, SQLiteDatabase]\"\u001B[39;00m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;66;03m# has no attribute \"read_table\"\u001B[39;00m\n\u001B[0;32m    286\u001B[0m table \u001B[38;5;241m=\u001B[39m pandas_sql\u001B[38;5;241m.\u001B[39mread_table(  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     table_name,\n\u001B[0;32m    288\u001B[0m     index_col\u001B[38;5;241m=\u001B[39mindex_col,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    292\u001B[0m     chunksize\u001B[38;5;241m=\u001B[39mchunksize,\n\u001B[0;32m    293\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: Table features not found"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql_table(table_name='features', con=engine.connect())\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='Region', hue='Segment', ax=ax, palette=sns.color_palette('hls', 3))\n",
    "ax.set_ylabel('Number of Orders')\n",
    "ax.set_title('Total Orders by Region and Segment')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**REMARK**: Similar to our Copier inquery from out Categorical Analysis, West- and East-coast consumers lead total orders (volume). Also of note, Corporate orders outpace Home Office volume in all four regions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selecting the 10 States with the most orders, aggregate Profit, and sort.\n",
    "T10 = df['State'].value_counts()[:10].index.tolist()\n",
    "top_state_df = df[df['State'].isin(T10)][['State', 'Profit']].groupby(by='State', as_index=False).sum().sort_values(by='Profit', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot top_state_df\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.barplot(data=top_state_df, x='Profit', y='State', orient='h', ax=ax)\n",
    "ax.set_title('Top-Performing US States')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**REMARK**: Unsurprisingly, California and New York compete for most Profitable (which here relates to most orders. Washington makes up roughly half of either, but Texas doesn't even make the Top 5."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KMeans Clustering\n",
    "\n",
    "SKLearn's OneHotEncoder may work too, but for our purposes, we're gonna do this quick and dirty."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Detect columns as either numeric or categorical\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print('Categorical Features:', cat_cols)\n",
    "#cat_cols.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Encode categorical data with dummy variables, normalize numerical features, then concatenate back together.\n",
    "norm_df = pd.concat([df[num_cols].apply(st.zscore), pd.get_dummies(df[cat_cols])], axis=1)\n",
    "norm_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Correct a TypeError\n",
    "norm_df.columns = norm_df.columns.astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inertial_vals = []\n",
    "\n",
    "K_vals  = range(1, 10)\n",
    "for k in K_vals:\n",
    "    kmeans = KMeans(k)\n",
    "    kmeans.fit(norm_df)\n",
    "    inertial_vals.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(K_vals, inertial_vals, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Sum of Squared Distances (Inertia)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=101).fit(norm_df)\n",
    "df['Cluster'] = kmeans.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Cluster'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Replace features to include 'Cluster'\n",
    "df.to_sql(name='features', con=engine, if_exists='append', index=False, chunksize=1000, method='multi')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
